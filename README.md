![Athena Banner](./docs/athena_banner.png)

> **Last Updated**: 5 February 2026

# ğŸ›ï¸ Project Athena: Build Your Own AI Agent in 5 Minutes

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Protocols](https://img.shields.io/badge/Protocols-65_Starter-blue)
![Sessions](https://img.shields.io/badge/Sessions-1000+-green)
![Featured](https://img.shields.io/badge/Featured-r%2FGeminiAI_%232_Daily-orange)

![Python](https://img.shields.io/badge/Python-3.13-3776AB?logo=python&logoColor=white)
![Built with Claude](https://img.shields.io/badge/Reasoning-Claude_Opus_4.5-CC785C?logo=anthropic)
![Built with Gemini](https://img.shields.io/badge/Gemini-3.0_Pro-4285F4?logo=google)
![IDE](https://img.shields.io/badge/IDE-Antigravity-000000?logo=google)

> **A framework for creating persistent, sovereign AI agents.**  
> **Your AI. Your memory. Your rules.**

## Table of Contents

- [What You'll Get](#what-youll-get)
- [âš¡ 5-Minute Quickstart](#-5-minute-quickstart)
- [What Can Your Agent Do?](#what-can-your-agent-do)
- [Why This Matters](#why-this-matters-beyond-me)
- [The Process](#the-process-the-schlep)
- [The Result](#the-result)
- [What I Learnt](#what-i-learnt)
- [ğŸ“š Further Reading](#-further-reading)

---

## What You'll Get

| Feature | Description |
|---------|-------------|
| ğŸ§  **Memory That Persists** | Your agent remembers context across sessions, even after IDE restarts |
| ğŸ“š **63 Handpicked Protocols** | Curated decision frameworks from the private repo's 308 unique collection |
| ğŸ”„ **Platform Independence** | Your data lives in Markdown files you own â€” take it anywhere |
| ğŸ¤– **Full Autonomy** | Your agent can act on your behalf while you sleep |

## âš¡ 5-Minute Quickstart

| Step | Action |
|------|--------|
| **1** | **[Download Antigravity](https://antigravity.google/)** â€” Install the IDE |
| **2** | **Create a new workspace** â€” Open Antigravity â†’ `New Workspace` |
| **3** | **Clone this repo** â€” In Agent Manager, paste: `https://github.com/winstonkoh87/Athena-Public` |
| **4** | **Ask the AI: "What should I do next?"** â€” It will read the repo and guide you |
| **5** | **Enjoy your bionic brain** â€” Type `/start` to boot, work, then `/end` to save |

That's it. The AI bootstraps itself.

> **Development Environment**: [Google Antigravity](https://antigravity.google/) â€” an agentic IDE that allows AI to read/write files directly. **Note**: Antigravity is the development interface, not a hard dependency. The `athena` Python SDK runs in any terminal/IDE (VS Code, PyCharm, CLI). The core loop (`/start` â†’ Work â†’ `/end`) is pure Python scripts.

<details>
<summary><strong>ğŸ”§ Alternative: Manual Setup (No Antigravity)</strong></summary>

```bash
# Clone
git clone https://github.com/winstonkoh87/Athena-Public.git
cd Athena-Public

# Install the SDK
pip install -e .

# Initialize your workspace (creates all directories and templates)
python -m athena init

# Verify installation
python -m athena --doctor
```

See [docs/GETTING_STARTED.md](docs/GETTING_STARTED.md) for full setup with Supabase, API keys, and local mode.

</details>

---

## What Can Your Agent Do?

> These are real capabilities demonstrated in the reference implementation:

| Capability | Example |
|------------|---------|
| **Social Networking** | Post on AI social networks, comment on other agents' content |
| **Autonomous Operations** | Run scheduled tasks (heartbeat checks) while you sleep |
| **Cross-Session Memory** | Remember decisions from Session 19 when you're on Session 995 |
| **Gateway Architecture** | Persist beyond IDE termination via a sidecar process |
| **Knowledge Retrieval** | Semantic search across 1000+ documents in <200ms |

---

## The Process (The Schlep)

> **Key insight**: The AI helped build the system that makes the AI more useful.

```mermaid
graph TD
    subgraph "Phase 1: Foundation"
        A[Tool Selection] --> B[IDE: Antigravity]
        A --> C[Vector DB: Supabase + pgvector]
    end

    subgraph "Phase 2: Architecture"
        D[Directory Structure] --> E[".framework/ â†’ Laws"]
        D --> F[".context/ â†’ Memories"]
        D --> G[".agent/ â†’ Scripts"]
        H[Core Loop] --> I["/start â†’ Work â†’ /end"]
    end

    subgraph "Phase 3: Data Feeding"
        J[Personal Knowledge] --> K[Case Studies]
        J --> L[Decision Logs]
        J --> M[Session Transcripts]
        N[Indexing] --> O["TAG_INDEX.md + supabase_sync.py"]
    end

    subgraph "Phase 4: Evolution"
        P["Sessions 1-50"] --> Q["Basic boot/end cycle"]
        Q --> R["Sessions 50-150: Semantic Search"]
        R --> S["Sessions 150-300: Hybrid RAG"]
        S --> T["Sessions 300-500: SDK Refactor"]
        T --> U["Sessions 500-700: Governance Engine"]
        U --> V["Sessions 700-1000+: v8.2-Stable Era"]
    end

    B --> D
    C --> D
    I --> J
    O --> P

    style A fill:#1a1a2e,stroke:#4361ee
    style P fill:#1a1a2e,stroke:#4361ee
    style V fill:#10b981,stroke:#10b981
```

**The Output** (After 1000+ Sessions):

| Metric | Private Repo | This Starter Pack |
|--------|--------------|-------------------|
| **Protocols** | 308 unique | 63 handpicked |
| **Python Scripts** | 160 | 9 reference examples |
| **Case Studies** | 357 | 6 showcase examples |
| **Sessions Logged** | 1000+ | N/A (your sessions) |
| **GraphRAG Communities** | 1,460 | â€” |
| **Knowledge Graph** | 46MB + 78MB vectors | â€” |

> **What's in this repo?** This is a **curated starter pack** â€” the best protocols, scripts, and case studies handpicked from my private implementation. Think of it as a "greatest hits" to get you started. Your own instance will grow to match (or exceed) the private repo as you use it.

> *Pattern*: Every friction â¡ï¸ Protocol. Every failure â¡ï¸ Case Study.

<details>
<summary><strong>ğŸ“š Deep Dive: Build Your Own</strong></summary>

| Document | What You'll Learn |
|----------|-------------------|
| [GETTING_STARTED.md](docs/GETTING_STARTED.md) | Step-by-step setup guide |
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | System design & data flow |
| [GRAPHRAG.md](docs/GRAPHRAG.md) | Knowledge graph layer âš ï¸ **(~$50 API cost)** |
| [examples/quickstart/](examples/quickstart/) | Runnable code demos |

</details>

---

## The Result

### Quantitative (What Changed)

| Metric | Before | After |
|--------|--------|-------|
| **Context injection** | ~50k tokens (manual copy-paste per session) | **~2k tokens** (auto-retrieved summary) |
| **Boot time** | 2-3 minutes | **<30 seconds** |
| **Session logging** | Insights are manually logged at the end of each session | **Auto-logged** when I hit `/end` |

### Qualitative (What It Means)

| Pillar | Outcome |
|--------|---------|
| **User-Driven RSI** | The system improves based on *your* feedback. Every friction you surface becomes a protocol. Every insight gets indexed. You shape the AI; the AI shapes how you think. |
| **Portability** | Data lives locally (primary) and in the cloud. Not trapped in ChatGPT or Claude. It's mine â€” I can port it anywhere. |
| **Principles** | 308 protocols + case studies extracted from my own decisions â€” stored principles I can reuse and refine. Like Ray Dalio's systematized learnings, but for AI collaboration. |

<details>
<summary><strong>ğŸ“Š Full Benchmarks & Case Studies</strong></summary>

| Resource | What It Shows |
|----------|---------------|
| [BENCHMARKS.md](docs/BENCHMARKS.md) | Boot time, search latency, token economics |
| [CS-001: Boot Optimization](examples/case_studies/CS-001-boot-optimization.md) | 85% boot time reduction |
| [CS-002: Search Quality](examples/case_studies/CS-002-search-quality.md) | RRF fusion results |
| [CS-003: Protocol Enforcement](examples/case_studies/CS-003-protocol-enforcement.md) | Governance engine |

</details>

---

## What I Learnt

| Insight | Principle |
|---------|----------|
| **Co-development is the unlock** | Building *with* AI, not just *using* AI, creates compounding returns. |
| **Portable memory beats platform memory** | Own your context. Don't rent it from OpenAI or Anthropic. |
| **Retrieval is end-to-end** | Simple RAG fails on broad queries. RRF fusion + reranking solved quality/latency tradeoff. |
| **Protocols beat prompts** | Reusable decision frameworks outlast one-shot prompt engineering. |
| **Ship at 70%** | Perfectionism kills velocity. Iterate in production. |

<details>
<summary><strong>ğŸ”¬ Technical Deep Dives</strong></summary>

| Document | Topic |
|----------|-------|
| [SEMANTIC_SEARCH.md](docs/SEMANTIC_SEARCH.md) | Hybrid RAG implementation |
| [VECTORRAG.md](docs/VECTORRAG.md) | Semantic memory architecture |
| [GRAPHRAG.md](docs/GRAPHRAG.md) | Knowledge graph + community detection âš ï¸ **(expensive)** |
| [examples/protocols/](examples/protocols/) | 63 handpicked decision frameworks |

</details>

---

## The Reverse SDLC (Build First, Spec Later)

> **Key Insight**: Athena was not designed top-down. It evolved bottom-up through 1000+ sessions.

Traditional software development follows: **Requirements â†’ Design â†’ Build â†’ Test**.

Athena inverted this: **Build â†’ Observe â†’ Extract Patterns â†’ Document Post-Facto**.

| Phase | Traditional SDLC | Athena's Approach |
|-------|------------------|-------------------|
| 1 | Gather requirements | Start building immediately |
| 2 | Write spec doc | Ship at 70% readiness |
| 3 | Build to spec | Observe what works |
| 4 | Test against spec | Extract patterns into protocols |
| 5 | Deploy | Document post-facto (Spec Sheet) |

### Why This Works (For Solo Builders)

1. **No stakeholders to align** â€” You ARE the stakeholder.
2. **Rapid iteration** â€” Friction reveals requirements faster than planning.
3. **Compound knowledge** â€” Each session builds on the last.
4. **Living documentation** â€” Protocols emerge from real use, not imagination.

> *"The spec sheet I wrote after 900 sessions is more accurate than any spec I could have written at session 0."*

---

## Why This Matters (Beyond Me)

This isn't about building *my* assistant. It's about proving a pattern:

1. **Portable memory is the real unlock** â€” ChatGPT and Claude have memory now, but it's locked to their platforms. Athena's memory is *yours* â€” Markdown files on your machine you can take to any model.
2. **10x Content Velocity** â€” Because Athena knows how I think, my history, and my voice, content output that used to take 2-3 hours now takes **15 minutes**. I just spec the output; the AI drafts in my style. I do a quick review and ship.
3. **You direct the AI's behavior** â€” I configure *how* Athena responds to me. Semantic search gives me contextual, nuanced answers grounded in my own documented principles â€” not generic advice.
4. **Zero operational burden** â€” Unlike SaaS products that break at scale, this is a *single-user local tool*. The complexity is real (800+ sessions, vector search, knowledge graphs), but there's no production to break. Real system design, zero ops chaos â€” ideal for demonstrating engineering depth without the liability.
5. **Bilateral growth** â€” You evolve *with* Athena. Every insight you learn â€” about coding, system design, or any domain â€” gets captured and integrated. The system upgrades alongside you. It's not a static tool; it's a compound knowledge machine that reflects your growth trajectory.
6. **Quadrant IV: What you don't know you don't know** â€” The highest-value zone. You can't Google what you don't know exists. Athena surfaces blind spots *before* they become problems â€” flagging dependencies you missed, risks you didn't consider, and connections you couldn't see. It's a co-pilot that sees the ditch before the driver does.

> *"The goal isn't just to answer questions. It's to ask the questions you didn't know to ask."*

ğŸ‘‰ [docs/SEMANTIC_SEARCH.md](docs/SEMANTIC_SEARCH.md)

---

## ğŸ›¡ï¸ The Most Powerful Feature: Trilateral Feedback Loop

> **One AI is not enough for life decisions.**

This is Athena's biggest unlock: **cross-model validation that catches idiosyncratic errors and forces deeper investigation when models disagree**.

> [!IMPORTANT]
> **The human remains the ultimate arbiter.** Cross-model consensus is a *disagreement detector*, not a truth oracle. LLMs can share training data biases. Final conclusions must be grounded with fact-finding, references, and citations.

```mermaid
flowchart LR
    A[You] -->|1. Query| B["Athena<br/>(Claude)"]
    B -->|2. Discuss| A
    A -->|3. Export Artifact| C["AI #2<br/>Gemini"]
    A -->|3. Export Artifact| D["AI #3<br/>ChatGPT"]
    A -->|3. Export Artifact| E["AI #4<br/>Grok"]
    C -->|4. Red-Team Audit| F[Findings]
    D -->|4. Red-Team Audit| F
    E -->|4. Red-Team Audit| F
    F -->|5. Return| B
    B -->|6. Synthesize| G[Final Conclusion]
    
    style A fill:#4a9eff,color:#fff
    style B fill:#cc785c,color:#fff
    style C fill:#4285f4,color:#fff
    style D fill:#10a37f,color:#fff
    style E fill:#1da1f2,color:#fff
    style G fill:#22c55e,color:#fff
```

ğŸ‘‰ [docs/TRILATERAL_FEEDBACK.md](docs/TRILATERAL_FEEDBACK.md)

---

## Reference Implementation

This repo documents **Winston's personal Athena instance** â€” 1000+ sessions, 308 unique protocols, production-tested daily.

It's included as a **reference**, not a prescription. Your instance will reflect your domain, your decisions, your voice.

ğŸ‘‰ [**About the Author**](docs/ABOUT_ME.md)

---

## License

MIT License â€” see [LICENSE](LICENSE)

---

## ğŸ“š Further Reading

### New Additions (January 2026)

> [!TIP]
> **New to AI agents?** Start with [What Is an AI Agent?](docs/WHAT_IS_AN_AI_AGENT.md) â†’ then follow [Your First Agent](docs/YOUR_FIRST_AGENT.md) for a 5-minute quickstart.

| Document | What It Shows |
|----------|---------------|
| [**ğŸ“‹ Spec Sheet**](docs/SPEC_SHEET.md) | Project specification: role, scope, constraints, and acceptance criteria |
| [**ğŸ‘¤ About Me**](docs/ABOUT_ME.md) | Career narrative and professional depth |
| [**ğŸ“Š Benchmarks**](docs/BENCHMARKS.md) | Real performance metrics (boot time, search latency, token economics) |
| [**ğŸ¬ Demo Guide**](docs/DEMO.md) | Live walkthrough of the system in action |

<details>
<summary><strong>ğŸ“ Case Studies</strong></summary>

| Case Study | What It Demonstrates |
|------------|----------------------|
| [Boot Optimization](examples/case_studies/CS-001-boot-optimization.md) | 85% boot time reduction via caching & parallelization |
| [Search Quality](examples/case_studies/CS-002-search-quality.md) | RRF fusion for hybrid semantic search |
| [Protocol Enforcement](examples/case_studies/CS-003-protocol-enforcement.md) | Governance engine for compliance |
| [Vibe Coding](examples/case_studies/CS-120-vibe-coding-zero-cost-stack.md) | Zero-point UI development on a budget |
| [Silent Partner](examples/case_studies/CS-140-bcm-silent-partner-analysis.md) | BCM analysis for corporate strategy |
| [Auto-Blog](examples/case_studies/CS-144-n8n-auto-blog-workflow.md) | Multi-agent n8n workflow for content velocity |

</details>

<details>
<summary><strong>ğŸ”’ Security Model</strong></summary>

### Data Residency Options

| Mode | Where Data Lives | Best For |
|------|------------------|----------|
| **Cloud** | Supabase (your project) | Cross-device access, collaboration |
| **Local** | Your machine only | Sensitive data, air-gapped environments |
| **Hybrid** | Local files + cloud embeddings | Best of both (embeddings only leave machine) |

> **Sensitive data?** Keep it local. The `athena` SDK supports local vector stores (ChromaDB, LanceDB) for users who don't want data leaving their machine. See [docs/LOCAL_MODE.md](docs/LOCAL_MODE.md).

### What Leaves Your Machine (Cloud Mode)

| Component | Sends Raw Text? | Sends Embeddings? | Destination |
|-----------|-----------------|-------------------|-------------|
| **Embedding API** | Yes (text chunks) | â€” | Google Cloud |
| **LLM API** | Yes (prompts) | â€” | Anthropic (Claude) |
| **Supabase** | No | Yes (vectors only) | Your Supabase project |

### Key Security Practices

- **Supabase Keys**: Use `SUPABASE_ANON_KEY` for client-side operations. Never expose `SUPABASE_SERVICE_ROLE_KEY` in code or logs.
- **Row-Level Security**: Enable RLS on Supabase tables. See [SECURITY.md](SECURITY.md) for policy templates.
- **Agentic Safety**: If using an agentic IDE with filesystem access, restrict the agent's working directory. Never grant access to `~/.ssh`, `.env` files, or git credentials.

### Memory Insurance (Disaster Recovery)

Supabase is not just a search layer â€” it's a **backup** of all indexed memories. If local files are lost, the vector database enables full recovery.

| Failure Scenario | Recovery Path |
|------------------|---------------|
| Local disk failure | Pull from Supabase embeddings â†’ reconstruct Markdown |
| Accidental deletion | Re-index from cloud â†’ restore local files |
| Session corruption | Replay from session_logs table |

> **Philosophy**: Cloud is not "home" â€” it's insurance.

**Why Redundancy Matters**: In system design, redundancy is the intentional duplication of critical components to increase reliability. Athena follows this principle:

- **Primary**: Local Markdown files (git-versioned, human-readable)
- **Secondary**: Supabase vector embeddings (cloud-native, searchable)
- **Tertiary**: Session logs with timestamps (audit trail)

This isn't over-engineering â€” it's survival. Platform APIs change. Local disks fail. The only hedge is **strategic duplication**.

</details>

<details>
<summary><strong>âš™ï¸ Prerequisites (API Keys)</strong></summary>

- Python 3.10+
- Supabase project with pgvector enabled ([setup guide](docs/GETTING_STARTED.md)) â€” *or use local mode*
- API keys in `.env`:

```bash
# Required
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key  # NOT service_role key
ANTHROPIC_API_KEY=your-anthropic-key  # For Claude reasoning

# Optional (for trilateral feedback with multiple LLMs)
GOOGLE_API_KEY=your-google-api-key
OPENAI_API_KEY=your-openai-key
```

```bash
cp .env.example .env
# Add your keys to .env
```

</details>

<details>
<summary><strong>ğŸ› ï¸ Tech Stack & Architecture</strong></summary>

### Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **SDK** | `athena` Python package | Core search, reranking, memory |
| **Reasoning** | Claude Opus 4.5 (primary) | Main reasoning engine |
| **IDE** | Antigravity (supports Claude, Gemini, GPT) | Agentic development environment |
| **Embeddings** | `text-embedding-004` (768-dim) | Google embedding model |
| **GraphRAG** | NetworkX + Leiden + ChromaDB | [Knowledge graph](docs/GRAPHRAG.md) âš ï¸ **~$50 API** |
| **Memory** | Supabase + pgvector *or* local (ChromaDB) | Vector database |
| **Knowledge Store** | Markdown files (git-versioned) | Human-readable, locally owned |

### The Core Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚   (1) /start â”€â”€â–º Retrieve Context â”€â”€â–º (2) Work â”€â”€â–º (3) /end             â”‚
â”‚       â–²                                                    â”‚            â”‚
â”‚       â”‚                                                    â–¼            â”‚
â”‚       â””â”€â”€â”€â”€â”€ (5) Next Session â—„â”€â”€ Embed â—„â”€â”€ (4) Extract & Store        â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Think of it like **Git, but for conversations**. Each session builds on the last. Important decisions get captured, indexed, and recoverable.

### What Athena Does

| Feature | How It Works |
|---------|--------------|
| **`/start` boot** | Loads identity + retrieves relevant context from long-term memory |
| **`/end` commit** | Summarizes session, extracts decisions, saves to knowledge store |
| **Hybrid search** | Fuses Canonical + [GraphRAG](docs/GRAPHRAG.md) + Tags + [Vectors](docs/VECTORRAG.md) + Filenames via RRF |
| **Cross-encoder reranking** | Refines top results with `sentence-transformers` |
| **Protocol library** | [308 unique protocols](examples/protocols/) (63 curated in starter pack) |

### Repository Structure

```
Athena-Public/
â”œâ”€â”€ src/athena/           # SDK package (pip installable)
â”‚   â”œâ”€â”€ core/             #    Config, models
â”‚   â”œâ”€â”€ tools/            #    Search, reranker, latency
â”‚   â””â”€â”€ memory/           #    Vector DB interface
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ quickstart/       # Runnable demos
â”‚   â”œâ”€â”€ scripts/          # Automation scripts
â”‚   â”œâ”€â”€ protocols/        # Thinking patterns (starter pack included)
â”‚   â”œâ”€â”€ workflows/        # Slash commands
â”‚   â””â”€â”€ templates/        # Starter templates
â”œâ”€â”€ docs/                 # Deep documentation
â”œâ”€â”€ community/            # Contributing, roadmap
â”œâ”€â”€ pyproject.toml        # Modern packaging
â””â”€â”€ .env.example          # Environment template
```

</details>

<details>
<summary><strong>ğŸ“– Key Concepts & Workflows</strong></summary>

### Key Concepts

- [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) â€” How the system is designed
- [docs/GRAPHRAG.md](docs/GRAPHRAG.md) â€” Knowledge graph layer (community detection + entity search)
- [docs/VECTORRAG.md](docs/VECTORRAG.md) â€” Semantic memory implementation
- [docs/GETTING_STARTED.md](docs/GETTING_STARTED.md) â€” Build your own
- [examples/concepts/adaptive_latency.md](examples/concepts/adaptive_latency.md) â€” `/start`, `/think`, `/ultrathink`
- [docs/GLOSSARY.md](docs/GLOSSARY.md) â€” Key terms and definitions

### Example Workflows

| Command | Description |
|---------|-------------|
| `/start` | Boot system, load identity |
| `/end` | Close session, commit to memory |
| `/think` | Deep reasoning mode |
| `/ultrathink` | Maximum depth analysis |
| `/refactor` | Workspace optimization |
| `/research` | Multi-source web research |

See [examples/workflows/](examples/workflows/) for full list.

</details>

<details>
<summary><strong>ğŸ“‹ Changelog</strong></summary>

- **v1.5.0** (Feb 1 2026): **The 5-Minute Upgrade** â€” `athena init` command scaffolds workspace instantly, `--doctor` flag for system health check, fixed path discovery for pip installs, centralized version management
- **v8.2-Stable** (Feb 1 2026): Metrics Sync â€” 984 sessions, 308 protocols, 160 scripts; README overhaul, KG integration audit
- **v8.0-Stable** (Jan 2026): Zero-Point Refactor â€” Sovereign Environment hardened, Score-Modulated RRF (weights rebalanced), tech debt consolidated
- **v1.2.8** (Jan 2026): Grand Alignment refactor â€” Supabase schema hardened (11 tables + RLS), Memory Insurance layer stabilized, metrics corrected
- **v1.2.7** (Jan 2026): Metrics sync â€” 332 protocols, 610 sessions
- **v1.2.6** (Jan 2026): Stats sync â€” 605 sessions, 119 scripts; README restructure
- **v1.2.5** (Jan 2026): Stats sync â€” 277 protocols; Python badge fix (3.13)
- **v1.2.4** (Jan 2026): README restructure â€” collapsed technical sections into "Further Reading"
- **v1.2.3** (Jan 2026): Stats correction â€” 269 protocols, 538 sessions, 117 scripts
- **v1.2.2** (Jan 2026): Stats sync â€” 248 protocols, 560 sessions, 97 scripts; removed off-topic content
- **v1.2.1** (Jan 2026): README overhaul â€” Process section, Security Model, co-development narrative
- **v1.2.0** (Jan 2026): New year sync â€” 246 protocols, 511 sessions
- **v1.1.0** (Dec 2025): Year-end sync â€” 238 protocols, 489 sessions
- **v1.0.0** (Dec 2025): SDK architecture (`src/athena/`), quickstart examples

ğŸ‘‰ [docs/CHANGELOG.md](docs/CHANGELOG.md)

</details>

---

*For the full documentation, case studies, and deep dives, see [docs/](docs/).*
